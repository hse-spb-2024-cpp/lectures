# Общее

Закон Мура: https://ru.wikipedia.org/wiki/%D0%97%D0%B0%D0%BA%D0%BE%D0%BD_%D0%9C%D1%83%D1%80%D0%B0
2004 год: 2.8 ГГц (Pentium 4 Prescoot)
С тех пор скорость работы повышалась, но другими способами: размер кэша, скорость памяти, периферии...
Уже уткнулись в ограничения размера процессора из-за скорости света.

# Параллелизм
## Конвейеризация
```
int x = a * b * 10;  // Нужен блок умножения.
int y = a / b;       // Нужен блок деления.
```

## Процессы
Процесс — одна выполняющаяся программа со своими ресурсами: выделенная память,
загруженный код, открытые файлы, установленные сетевые соединения...

## Поток выполнения
Нить выполнения, thread, тред, трэд.

У каждого потока есть свой стек вызовов: локальные переменные, вызванные функции.
Остальное у потоков общее, берётся от процесса: глобальные переменные, адреса
в памяти, открытые файлы...

Исходно есть один поток (главный), можно явно создавать новые.

# Зачем
## Ускорение работы
Только если есть несколько физических ядер/процессоров.

Параллелится хорошо:
```
int sum = 0;
for (int x : values) sum += x;
```

Параллелится хоть на уровне железа:

```
char buf1[100], buf2[100];
fread(file_on_disk1, 1, sizeof buf1, buf1);
fread(file_on_disk2, 1, sizeof buf2, buf2);
```

Не параллелится:

```
int steps = 0;
for (int x = 1; x != 0; x = f(x)); steps++;
```

Для распределённых вычислений есть отдельные алгоритмы.
Иногда "наивное" решение проще распараллелить чем умное.

## Упрощение кода
Даже если одно ядро, то можно делать несколько задач одновременно.
И быстро между ними переключаться "прозрачно" для программы.
